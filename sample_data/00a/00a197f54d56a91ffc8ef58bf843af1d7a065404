% fcn is the cost function
% x0 is initial theta
% options is the structure of gradient descent settings
function [theta, theta_history, J_history] = gradientDescent(fcn, X0, options)
  
  
% Initialize some useful values
theta = X0;
theta_history = zeros(size(theta, 1), options.iters);
J_history = zeros(1, options.iters);

for iter = 1 : options.iters 
  [J, gradient] = fcn(theta);
  J_history(iter) = J;
  theta_history(:, iter) = theta;
  theta = theta - (options.alpha * gradient);
  %diff = abs(theta - thetaHistory(:,iter));
  
 % if (J < options.minCost)
  %  J_history = J_history(1:iter);  
   % thetaHistory = thetaHistory(:,1:iter);
   % break;
 % end
  
  %if (sum(diff) < options.minThetaDiff)
   % J_history = J_history(1:iter);  
   % thetaHistory = thetaHistory(:,1:iter);
  %  break;
  %end

end  
  

end